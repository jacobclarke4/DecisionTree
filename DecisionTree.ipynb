{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Jacob Clarke\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "splitIGList = []\n",
    "#Function that calculates entropy based on formula given in class\n",
    "#parameter probability, calculated from formula given in class\n",
    "#returns the entropy or unknown \n",
    "def ent(probability):\n",
    "    \n",
    "    entropy = 0\n",
    "    \n",
    "    if probability != 0:\n",
    "        entropy = (-1)*(probability * math.log2(probability))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "#Functions that calculates probability based on formula given in class\n",
    "#parameter is the numerator (p + n)/ denominator (total values)\n",
    "#return the probability of the number in parameter\n",
    "def prob(num,total):\n",
    "    \n",
    "    probability = 0\n",
    "    \n",
    "    if num != 0:\n",
    "        probability = num/total\n",
    "        \n",
    "    return probability\n",
    "\n",
    "def informationGain(data_frame):\n",
    "    \n",
    "    length = len(data_frame)\n",
    "    attributes = data_frame.columns\n",
    "    numCol = len(attributes) - 1\n",
    "    startingEntropy = 0\n",
    "    \n",
    "    #create a list of the target attribute column\n",
    "    #use the list to create a dictionary of targets\n",
    "    dfToList = list(data_frame[attributes[numCol]])\n",
    "    target_dict = {i:dfToList.count(i) for i in dfToList}\n",
    "    dleng = len(target_dict)\n",
    "    targets = target_dict.keys()\n",
    "    targetsv = target_dict.values()\n",
    "    \n",
    "    #calculate the starting entropy \n",
    "    for value in target_dict.values():\n",
    "        temp = prob(value,length)\n",
    "        startingEntropy = startingEntropy + (temp*math.log2(temp))\n",
    "    startingEntropy = startingEntropy*(-1)\n",
    "    \n",
    "    #print(startingEntropy)\n",
    "\n",
    "    data = data_frame.to_numpy()\n",
    "    infoGain = startingEntropy\n",
    "    split = 0\n",
    "    midpoint = 0\n",
    "    remainder = 0\n",
    "    count = 0\n",
    "    \n",
    "    #Create VGT and VLEQ Dictionary\n",
    "    #VGT has all values to begin with and VLEQ have 0 values\n",
    "    VGT_dict = copy.deepcopy(target_dict)\n",
    "    VLEQ_dict = {}\n",
    "    for k in VGT_dict:\n",
    "        VLEQ_dict[k] = 0\n",
    "        \n",
    "    bestInfoGain = 0\n",
    "    bestSplitOverall = 0\n",
    "    bestTitleOverall = \"\"\n",
    "    #Loop that will go through each column in the data set\n",
    "    for i in attributes:\n",
    "        \n",
    "        #will hold the best split value for continuo\n",
    "        bestSplit = 0\n",
    "        bestTitle = \"\"\n",
    "        \n",
    "        tempVGT_dict = copy.deepcopy(VGT_dict)\n",
    "        tempVLEQ_dict = copy.deepcopy(VLEQ_dict)\n",
    "        #hold the biggest information gain for continuous attribute\n",
    "        bestConInfoGain = 0\n",
    "\n",
    "        #Makes sure to not calculate information gain for the target attribute column\n",
    "        if i != attributes[numCol]:\n",
    "            #sort the data_frame by comlumn\n",
    "            data_frame = data_frame.sort_values(i)\n",
    "            data = data_frame.to_numpy()\n",
    "            \n",
    "            #make a list of values from the current attribute column\n",
    "            attrList = list(data_frame[attributes[count]])\n",
    "            \n",
    "            #dictionary of the values in the attribute list\n",
    "            temp_dict = {i:attrList.count(i) for i in attrList}\n",
    "            tLength = len(temp_dict)\n",
    "            \n",
    "            #list of all the values in the target column that correspond with the sorted attribute\n",
    "            classList = list(data_frame[attributes[numCol]])\n",
    "            class_dict = {i:classList.count(i) for i in classList}\n",
    "           \n",
    "            #if length of temp_dict is 2 than there are 2 possible values \n",
    "            if tLength == 2:\n",
    "                \n",
    "                #reset tempinfoGain\n",
    "                tempinfoGain = startingEntropy\n",
    "                \n",
    "                #create a dicitonary for 0 and 1 attribute value\n",
    "                tempAttr0_dict = {}\n",
    "                tempAttr1_dict = {}\n",
    "                tempAttr0Ent = 0\n",
    "                tempAttr1Ent = 0\n",
    "                tempSplit = .5\n",
    "                \n",
    "                #create a key in the dictionarys for the amount of values in the target class\n",
    "                for k in class_dict:\n",
    "                    tempAttr0_dict[k] = 0\n",
    "                    tempAttr1_dict[k] = 0\n",
    "                    bestTitle = i\n",
    "                \n",
    "                #Make a count of the number of class values for each binary number    \n",
    "                for t in range(length):\n",
    "                    temp = classList[t]\n",
    "                    if attrList[t] == 0:\n",
    "                        tempAttr0_dict[temp] += 1\n",
    "\n",
    "                    elif attrList[t] == 1:\n",
    "                        tempAttr1_dict[temp] += 1\n",
    "\n",
    "                #calculates the entropy based on the binary values\n",
    "                for k in tempAttr0_dict:\n",
    "                    tempAttr0 = tempAttr0_dict[k]\n",
    "                    tempAttr1 = tempAttr1_dict[k]\n",
    "                    tempAttr0Ent = tempAttr0Ent + ent(prob(tempAttr0, sum(tempAttr0_dict.values())))\n",
    "                    tempAttr1Ent = tempAttr1Ent + ent(prob(tempAttr1, sum(tempAttr1_dict.values())))\n",
    "                    \n",
    "                #calculate the remainder from the entropys\n",
    "                remainder = (sum(tempAttr0_dict.values())/length)*(tempAttr0Ent) + (sum(tempAttr1_dict.values())/length)*(tempAttr1Ent)\n",
    "                \n",
    "                #calcluate the information gain from the \n",
    "                tempinfoGain = tempinfoGain - remainder\n",
    "                splitIGList.append(i)\n",
    "                splitIGList.append(tempSplit)\n",
    "                splitIGList.append(tempinfoGain)\n",
    "                if tempinfoGain > bestInfoGain:\n",
    "                    bestInfoGain = tempinfoGain\n",
    "                    bestSplitOverall = tempSplit\n",
    "                    bestTitleOverall = bestTitle\n",
    "                \n",
    "            #continuous attribute\n",
    "            else:\n",
    "                \n",
    "                #loop through the length of the data set\n",
    "                for j in range(length):\n",
    "                    \n",
    "                    #calculates the midpoints between each continous value\n",
    "                    if j == 0:\n",
    "                        midpoint = float((data[0][count]))/2\n",
    "                    elif j != length - 1:\n",
    "                        midpoint = ((float(data[j-1][count])) + (float((data[j][count]))))/2\n",
    "                    else:\n",
    "                        midpoint = float((data[j][count]))\n",
    "                    #first split point has no values less than or equal to so there is no need\n",
    "                    #to calculate information gain\n",
    "                    if j == 0:\n",
    "                        tempVGT_dict[classList[j]] = tempVGT_dict[classList[j]] -1\n",
    "                        tempVLEQ_dict[classList[j]] = tempVLEQ_dict[classList[j]] + 1\n",
    "                    if j >0:   \n",
    "                        #if 2 adjacent class values are different than this split can be considered\n",
    "                        #a best split candidate and information gain should be calculated\n",
    "                        if data[j-1][numCol] != data[j][numCol]:\n",
    "                            tempinfoGain = startingEntropy\n",
    "                            tempSplit = midpoint\n",
    "                            tempTitle = i\n",
    "                            tempVGTtotal = 0\n",
    "                            tempVlEQtotal = 0\n",
    "                            tempVGTEnt = 0\n",
    "                            tempVLEQEnt = 0\n",
    "                            infoGain = 0\n",
    "                            remainder = 0\n",
    "                            \n",
    "                            #Move through the dictionarys and calculate the entropy for VLEQ and VGT\n",
    "                            for k in tempVGT_dict:\n",
    "                                tempVGT = tempVGT_dict[k]\n",
    "                                tempVLEQ = tempVLEQ_dict[k]\n",
    "                                tempVGTEnt = tempVGTEnt + ent(prob(tempVGT, sum(tempVGT_dict.values())))\n",
    "                                tempVLEQEnt = tempVLEQEnt + ent(prob(tempVLEQ, sum(tempVLEQ_dict.values())))\n",
    "                            \n",
    "                            #calculate the remainder from the entropy of VLEQ and VGT\n",
    "                            remainder = (sum(tempVGT_dict.values())/length)*(tempVGTEnt) + (sum(tempVLEQ_dict.values())/length)*(tempVLEQEnt)\n",
    "                            \n",
    "                            #calculate the information gain\n",
    "                            tempinfoGain = tempinfoGain - remainder\n",
    "                            if tempinfoGain > bestConInfoGain:\n",
    "                                bestSplit = tempSplit\n",
    "                                bestConInfoGain = tempinfoGain\n",
    "                                bestTitle = tempTitle\n",
    "\n",
    "                        tempVGT_dict[classList[j]] = tempVGT_dict[classList[j]] -1\n",
    "                        tempVLEQ_dict[classList[j]] = tempVLEQ_dict[classList[j]] + 1\n",
    "                splitIGList.append(i)\n",
    "                splitIGList.append(bestSplit)\n",
    "                splitIGList.append(bestConInfoGain)\n",
    "                if bestConInfoGain > bestInfoGain:\n",
    "                    bestInfoGain = bestConInfoGain\n",
    "                    bestSplitOverall = bestSplit\n",
    "                    bestTitleOverall = bestTitle\n",
    "            \n",
    "            \n",
    "            bestListOverall = [bestTitleOverall, bestSplitOverall, bestInfoGain]\n",
    "            \n",
    "        \n",
    "            count = count + 1\n",
    "    \n",
    "\n",
    "    return bestListOverall\n",
    "\n",
    "class DecisionTree():\n",
    "    max_depth = 3\n",
    "    root = None\n",
    "    #constructor\n",
    "    def __init__(self, max_depth, rooty):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = rooty\n",
    "     # end __init__\n",
    "    \n",
    "    #set,get methods for Decision Tree \n",
    "    def getRoot(self):\n",
    "        return self.root\n",
    "    \n",
    "    def setRoot(self, rooty):\n",
    "        self.root = rooty\n",
    "        \n",
    "    def getDepth(self):\n",
    "        return self.max_depth\n",
    "\n",
    "    def __decision_tree_learning(self, examples, parent_examples, currentDepth, maxDepth):\n",
    "        #variables to help with base cases\n",
    "        exAttributes = examples.columns  #Series of attribute names           \n",
    "        numColEx = len(exAttributes)-1  #length of the series\n",
    "        exList = list(examples[exAttributes[numColEx]])  #List of all target values for examples\n",
    "        example_dict = {i:exList.count(i) for i in exList}  #Dictionary of target values\n",
    "        exampleLength = len(example_dict)  #Number of unique target values\n",
    "        \n",
    "        parentAttributes = parent_examples.columns  #Series of parent attribute names\n",
    "        numCol = len(parentAttributes)-1  #Length of the series \n",
    "        parentExList = list(parent_examples[parentAttributes[numCol]]) #List of all target values for parent Examples\n",
    "        parent_dict = {i:parentExList.count(i) for i in parentExList}  #Dictionary of all parent Example target values\n",
    "        \n",
    "        #base cases in DTL\n",
    "        if examples.empty:  #if no examples left\n",
    "            Node1 = Node(None, self.__plurality_value(parentExList, '?'), True)\n",
    "            return Node1\n",
    "        elif exampleLength == 1: #if dictionary is of length 1 then examples have all same target vals\n",
    "            Node2 = Node(None, (list(example_dict.keys())[0]), True)\n",
    "            return Node2\n",
    "        elif numColEx == 1: #No attributes but class column exists\n",
    "            Node3 = Node(None, self.__plurality_value(exList, '?'), True)\n",
    "            return Node3\n",
    "        elif currentDepth == maxDepth: #Max depth has been reached so leaf node must be created\n",
    "            Node4 = Node(None,self.__plurality_value(exList, '?'), True)\n",
    "            return Node4\n",
    "        else:\n",
    "            A = informationGain(examples)\n",
    "            root = Node(A[0],A[1], False)\n",
    "            \n",
    "            #examples to be dropped\n",
    "            rightDrop = []\n",
    "            leftDrop = []\n",
    "            #Goes through each row of the examples frame and compares value at best split attr to the best split in the Node\n",
    "            #if greater than, the row goes to rightDrop, if less than, rows go to leftdrop\n",
    "            for index in examples.index:\n",
    "                if ((float(examples[A[0]][index])) > A[1]):\n",
    "                    rightDrop.append(index)\n",
    "                else:\n",
    "                    leftDrop.append(index)\n",
    "            \n",
    "            #examples to use in child Nodes for left and right\n",
    "            rightExs = examples.drop(leftDrop)\n",
    "            leftExs = examples.drop(rightDrop)\n",
    "            \n",
    "            #drops the attribute column with best informationgain\n",
    "            rightExs = rightExs.drop(root.attr, axis = 1)\n",
    "            leftExs = leftExs.drop(root.attr, axis = 1)\n",
    "            \n",
    "            #Node Branches\n",
    "            root.right = self.__decision_tree_learning(rightExs, examples, currentDepth + 1, maxDepth)\n",
    "            root.left = self.__decision_tree_learning(leftExs, examples, currentDepth + 1, maxDepth)\n",
    "            \n",
    "            return root\n",
    "    \n",
    "    #method to build decision tree based on trainingset\n",
    "    def fit(self, T, maxDepth):\n",
    "        #fill in missing Values in the dataset with plurality values\n",
    "        self.__fill_missing_vals(T, '?')\n",
    "        \n",
    "        \n",
    "        #use decision tree learning to build the tree\n",
    "        root = self.__decision_tree_learning(T,T,0, maxDepth)\n",
    "        self.setRoot(root)\n",
    "        bac\n",
    "\n",
    "     # end fit\n",
    "    \n",
    "    #method to iterate through decision tree and make predictions from dataset given\n",
    "    def predict(self, T):\n",
    "        \n",
    "        \n",
    "        #fill in missing values of the data set\n",
    "        self.__fill_missing_vals(T, '?')\n",
    "        length = len(T)\n",
    "        predictedList = []\n",
    "        \n",
    "        #traverse the tree to make a prediction\n",
    "        for i in range(length):\n",
    "            row = T.loc[i]\n",
    "            #get the root of the fitted tree\n",
    "            tempNode = self.getRoot()\n",
    "            #Keep going through tree until you find a leaf\n",
    "            while(tempNode.getLeaf() == False):\n",
    "                attr = tempNode.getAttr()\n",
    "                count = 0\n",
    "                split = tempNode.getSplitVal()\n",
    "                found = False\n",
    "                while(found == False):\n",
    "                    for index in row.index:\n",
    "                        if index == attr:\n",
    "                            if float(row[index]) > split: #if value is bigger than split move right\n",
    "                                tempNode = tempNode.getRight()\n",
    "                                found = True\n",
    "                            else: #else, value is less than split so move left\n",
    "                                tempNode = tempNode.getLeft()\n",
    "                                found = True\n",
    "                        count = count + 1\n",
    "            #Once at a leaf Node the prediction is made\n",
    "            if (tempNode.getLeaf() == True):\n",
    "                predictedList.append(tempNode.getSplitVal())#Add the predicted value to a list\n",
    "        return predictedList\n",
    "                \n",
    "     # end predict\n",
    "    def print(self):\n",
    "        self.__print_bfs()\n",
    "     #end print\n",
    "\n",
    "     # Helper methods related to handling of missing values can be\n",
    "     # placed here. You may just copy methods from Homework2_Helper.py\n",
    "    def __fill_missing_vals(self, df, missing_indicator):\n",
    "        columns = df.columns.values\n",
    "        for col in columns:\n",
    "            col_vals = df[col].values\n",
    "\n",
    "            for i in range(len(col_vals)):\n",
    "                if col_vals[i] == missing_indicator:\n",
    "                    pvalue = self.__plurality_value(col_vals, missing_indicator)\n",
    "                    # Assuming here that we do not have to deal with columns that have\n",
    "                    # all of their values missing\n",
    "                    col_vals[i] = pvalue\n",
    "                # end if\n",
    "            # end inner for\n",
    "        # end outer for\n",
    "    # end __fill_missing_vals    \n",
    "\n",
    "    def __plurality_value(self, class_vals, missing_indicator):\n",
    "        class_vals_dict = self.__create_dict(class_vals, missing_indicator)\n",
    "        max_val = class_vals_dict[max(class_vals_dict, key=class_vals_dict.get)]\n",
    "\n",
    "        max_keys = []\n",
    "        for key, val in class_vals_dict.items():\n",
    "            if (val == max_val):\n",
    "                max_keys.append(key)\n",
    "        # end for\n",
    "        return random.choice(max_keys)\n",
    "    # end __plurality_value\n",
    "\n",
    "    def __create_dict(self, attr_vals, missing_indicator):\n",
    "        dict = {}\n",
    "        for val in attr_vals:\n",
    "            if val != missing_indicator:\n",
    "                if val in dict:\n",
    "                    dict[val] += 1\n",
    "                else:\n",
    "                    dict[val] = 1\n",
    "        return dict\n",
    "    # end __create_dict\n",
    "    \n",
    "    #https://stackoverflow.com/questions/1894846/printing-bfs-binary-tree-in-level-order-with-specific-formatting\n",
    "    #found this code online, and modified it to work with my code\n",
    "    def __print_bfs(self):\n",
    "        \n",
    "        #retreive root of the tree\n",
    "        root = self.getRoot()\n",
    "        \n",
    "        #this level is a list of all Nodes in bfs order, root is first by default\n",
    "        thislevel = [root]\n",
    "        while thislevel:\n",
    "            nextlevel = list()\n",
    "            #traverses the list by index\n",
    "            for n in thislevel:\n",
    "                #prints the attribute of the current Node\n",
    "                print(n.getAttr())\n",
    "                if n.left: #checks if Node has a left Node\n",
    "                    nextlevel.append(n.getLeft()) #adds the left Node to the List\n",
    "                if n.right: #checks if Node has a right Node\n",
    "                    nextlevel.append(n.getRight()) #adds right node to the list\n",
    "            print()\n",
    "            #changes thisLevel to represent the new level of nodes in the tree\n",
    "            thislevel = nextlevel\n",
    "\n",
    "class Node():\n",
    "    splitPoint = None\n",
    "    attr = None\n",
    "    leaf = False\n",
    "    left = None\n",
    "    right = None\n",
    "    #constructor of Node\n",
    "    #if my node will end up being a leaf, the prediction value would be stored in its splitPoint\n",
    "    def __init__(self,attr,splitVal, Leaf):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.splitPoint = splitVal  #will hold the predicion if leaf node\n",
    "        self.attr = attr\n",
    "        self.leaf = Leaf\n",
    "        \n",
    "    #set,get methods of Node    \n",
    "    def getSplitVal(self):\n",
    "        return self.splitPoint\n",
    "    \n",
    "    def setSplitVal(self,splitVal):\n",
    "        self.splitPoint = splitVal\n",
    "        \n",
    "    def getLeft(self):\n",
    "        return self.left\n",
    "    \n",
    "    def setLeft(self, newNode):\n",
    "        self.left = newNode\n",
    "        \n",
    "    def getRight(self):\n",
    "        return self.right\n",
    "    \n",
    "    def setRight(self, newNode):\n",
    "        self.right = newNode\n",
    "        \n",
    "    def getAttr(self):\n",
    "        return self.attr\n",
    "    \n",
    "    def getLeaf(self):\n",
    "        return self.leaf\n",
    "\n",
    " # __init__, setters, and getters go here\n",
    "# end class Node\n",
    "\n",
    "def accuracy(predictList, data_set):\n",
    "    #length of the dataset we are testing accuracy on\n",
    "    length = len(data_set)\n",
    "    \n",
    "    #series of attribute/column header\n",
    "    attributes = data_set.columns\n",
    "    \n",
    "    #last column that is represents the target column\n",
    "    numCol = len(attributes)-1\n",
    "    \n",
    "    #numerator is how many predictions correct\n",
    "    numerator = 0\n",
    "    #length is the total number of predictions\n",
    "    denominator = length\n",
    "    #percentage correct\n",
    "    percentage = 0\n",
    "    \n",
    "    #loop through data sets targets and predicted targets and test if they are eqaul\n",
    "    for i in range(length):\n",
    "        row = data_set.loc[i]\n",
    "        if predictList[i] == row[numCol]:\n",
    "            numerator = numerator + 1\n",
    "    percentage = (numerator/denominator)\n",
    "    return percentage\n",
    " # Return that percentage\n",
    "# end accuracy\n",
    "def validation_curve():\n",
    " # Read the arrhythmia.csv data set\n",
    "    data = pd.read_csv('arrhythmia.csv')\n",
    "\n",
    " # Randomly shuffle the examples in the dataset\n",
    "    data = data.sample(frac=1)\n",
    "    \n",
    "    lengthData = len(data)\n",
    "    \n",
    "    #length of partitions to be made\n",
    "    partition1Length = lengthData/3\n",
    "    partition1Length = int(partition1Length)\n",
    "    partition2Length = int((lengthData-partition1Length)/2)\n",
    "    partition3Length = int(lengthData - (partition1Length+partition2Length))\n",
    "    partList = [partition1Length, partition2Length, partition3Length]\n",
    "    \n",
    "    #where to separate each partition\n",
    "    part1 = partition1Length\n",
    "\n",
    "    part2 = (partition1Length+partition2Length)\n",
    "\n",
    "    part3 = part2 + partition3Length\n",
    "\n",
    "    #dataframes of equal size\n",
    "    partition1Frame = data[0:part1]\n",
    "    partition2Frame = data[part1:part2]\n",
    "    partition3Frame = data[part2:part3]\n",
    "\n",
    "    #list of all the depth levels\n",
    "    depthList = [2,4,6,8,10,12,14,16,18,20]\n",
    "    \n",
    "    #list of what combined trainingsets will be\n",
    "    t1 = [partition1Frame, partition2Frame]\n",
    "    t2 = [partition2Frame, partition3Frame]\n",
    "    t3 = [partition1Frame, partition3Frame]\n",
    "\n",
    "    #building of trainingsets and validation sets\n",
    "    training_set1 = pd.concat(t1)\n",
    "    training_set1 = training_set1.reset_index()\n",
    "    validation_set1 = partition3Frame\n",
    "    validation_set1 = validation_set1.reset_index()\n",
    "    \n",
    "    training_set2 = pd.concat(t2)\n",
    "    training_set2 = training_set2.reset_index()\n",
    "    validation_set2 = partition1Frame\n",
    "    validation_set2 = validation_set2.reset_index()\n",
    "    \n",
    "    training_set3 = pd.concat(t3)\n",
    "    training_set3 = training_set3.reset_index()\n",
    "    validation_set3 = partition2Frame\n",
    "    validation_set3 = validation_set3.reset_index()\n",
    "    \n",
    "    #lists to hold the percentage correct fo each ts and v\n",
    "    per1t = []\n",
    "    per1v = []\n",
    "    \n",
    "    per2t = []\n",
    "    per2v = []\n",
    "    \n",
    "    per3t = []\n",
    "    per3v = []\n",
    "    \n",
    "    #loop through each depth level and create trees using trainingsets as well as make predictions\n",
    "    for c in range((len(depthList))):\n",
    "        \n",
    "        #lists that hold the predictions made\n",
    "        classList1t = []\n",
    "        classList1v = []\n",
    "        \n",
    "        classList2t = []\n",
    "        classList2v = []\n",
    "        \n",
    "        classList3t = []\n",
    "        classList3v = []\n",
    "        \n",
    "        #Empty trees created with maxDepth\n",
    "        tree1 = DecisionTree(c, None)\n",
    "        tree2 = DecisionTree(c, None)\n",
    "        tree3 = DecisionTree(c, None)\n",
    "\n",
    "        #training and predictions for ts1 and v1\n",
    "        tree1.fit(training_set1, tree1.getDepth())\n",
    "        rootles = tree1.getRoot()\n",
    "        \n",
    "        classList1t = tree1.predict(training_set1)\n",
    "        \n",
    "        classList1v = tree1.predict(validation_set1)\n",
    "        \n",
    "        #accuracies for ts1 and v1\n",
    "        per1t.append(accuracy(classList1t,training_set1))\n",
    "        per1v.append(accuracy(classList1v,validation_set1))\n",
    "        \n",
    "        #training and predictions for ts2 and v2\n",
    "        tree2.fit(training_set2, tree2.getDepth())\n",
    "        \n",
    "        classList2t = tree2.predict(training_set2)\n",
    "        \n",
    "        classList2v = tree2.predict(validation_set2)\n",
    "        \n",
    "        #accuracies for ts2 and v2\n",
    "        per2t.append(accuracy(classList2t,training_set2))\n",
    "        per2v.append(accuracy(classList2v,validation_set2))\n",
    "\n",
    "        #training and predictions for ts3 and v3\n",
    "        tree3.fit(training_set3, tree3.getDepth())\n",
    "        \n",
    "        classList3t = tree3.predict(training_set3)\n",
    "        \n",
    "        classList3v = tree3.predict(validation_set3)\n",
    "        \n",
    "        #accuracies for ts3 and v3\n",
    "        per3t.append(accuracy(classList3t,training_set3))\n",
    "        per3v.append(accuracy(classList3v,validation_set3))\n",
    "        \n",
    "    #Lists that will hold the average values of all trainingsets and validationset accuracies\n",
    "    averageTSList = []\n",
    "    averageVList = []\n",
    "    #loops through the lists for trainingsets and validationsets and calculates average accuracy at each depth\n",
    "    for t in range(len(depthList)):\n",
    "        temp1 = per1t[t] + per2t[t] + per3t[t]\n",
    "        temp1 = (temp1)/3\n",
    "        averageTSList.append(temp1)\n",
    "        \n",
    "        temp2 = per1v[t] + per2v[t] + per3v[t]\n",
    "        temp2 = (temp2)/3\n",
    "        averageVList.append(temp2)\n",
    "        \n",
    "    #plot the data based on the data above\n",
    "    #t = plt.figure()\n",
    "    #code I used to plot each indivdual training set and validation set\n",
    "#     plt.plot(depthList,per1t)\n",
    "#     plt.plot(depthList,per1v)\n",
    "    \n",
    "#     plt.plot(depthList,per2t)\n",
    "#     plt.plot(depthList,per2v)\n",
    "    \n",
    "#     plt.plot(depthList,per3t)\n",
    "#     plt.plot(depthList,per3v)\n",
    "\n",
    "#plt.legend(['traininset1', 'validationset1', 'trainingset2', 'validationset2','trainingset3','validation3'], loc='upper left')\n",
    "    #Plot the averageTSList data and averageVList Data\n",
    "    t = plt.figure()\n",
    "    plt.plot(depthList,averageTSList)\n",
    "    plt.plot(depthList,averageVList)\n",
    "    \n",
    "    plt.legend(['Average Training Set', 'Average Validation Set'], loc='upper left')\n",
    "    plt.show()\n",
    "    t.savefig(\"Clarke_homework2.pdf\",bbox_inches='tight')\n",
    "    \n",
    "# call validation_curve or main\n",
    "validation_curve()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
